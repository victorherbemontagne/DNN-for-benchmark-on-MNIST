{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sbn\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "\n",
    "train = mnist.train.images\n",
    "target_train = mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code d'un rÃ©seau de neuronnes avec optimizer Adam, batch normalisation, relu\n",
    "n_neural_hidden_1 = 300\n",
    "n_neural_hidden_2 = 200\n",
    "training = True\n",
    "\n",
    "def echeancier_apprentissage(initial_learning_rate,decay_steps = 10000,decay_rate = 1/10):\n",
    "\n",
    "    return(learning_rate)\n",
    "    \n",
    "\n",
    "def neural_nets(data,target,batch_size=128,nbr_epoch=30,n_neural_hidden_1 = 300,n_neural_hidden_2 = 100,initial_learning_rate = 0.1,dropout_rate = 0.90,decay_steps = 10000,decay_rate = 1/10,training = True):\n",
    "    tf.reset_default_graph() \n",
    "    my_batch_normalisation_layer = partial(tf.layers.batch_normalization,training = training, momentum = 0.9)\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer(mode = 'FAN_AVG')\n",
    "    keep_prob = tf.constant(dropout_rate)\n",
    "    \n",
    "    input_nn = tf.placeholder('float',shape = (None,784))\n",
    "    target_nn = tf.placeholder('float',shape = (None,10))\n",
    "    \n",
    "    hidden_1 = tf.layers.dense(input_nn,n_neural_hidden_1,kernel_initializer = he_init, name = 'hidden1')\n",
    "#     batch_normed =my_batch_normalisation_layer(hidden_1)\n",
    "    batch_activated = tf.nn.selu(hidden_1)\n",
    "    batch_activated = tf.contrib.nn.alpha_dropout(batch_activated,keep_prob)\n",
    "    hidden_2 = tf.layers.dense(batch_activated,n_neural_hidden_2,kernel_initializer = he_init,name = 'hidden2')\n",
    "    batch_activated2 = tf.nn.selu(hidden_2)\n",
    "    batch_activated2 = tf.contrib.nn.alpha_dropout(batch_activated2,keep_prob)\n",
    "    \n",
    "    output = tf.layers.dense(batch_activated2,10,name = 'output')\n",
    "    y_pred = tf.nn.softmax(output,name='softmax_out')\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits = y_pred,labels = target_nn)\n",
    "    error = tf.reduce_mean(loss)\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate,global_step,decay_steps,decay_rate)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9,use_nesterov=True)\n",
    "    train_op = optimizer.minimize(error,global_step=global_step)\n",
    "    \n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        for epoch in range(nbr_epoch):\n",
    "            for batch in range(data.shape[0]//batch_size):\n",
    "                loss = sess.run([error,train_op,extra_update_ops], \n",
    "                                feed_dict={input_nn:data[128*batch:128*(batch+1)],\n",
    "                                           target_nn:target[128*batch:128*(batch+1)]}\n",
    "                               )[0]\n",
    "            print('Epoch {}, Loss de ->'.format(epoch),loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neural_nets(train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data processing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sbn\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mnist.train.images\n",
    "target_train = mnist.train.labels\n",
    "\n",
    "train_util = []\n",
    "target_train_util = []\n",
    "\n",
    "for k in range(train.shape[0]):\n",
    "    if np.sum(target_train[k][0:5]) != 0:\n",
    "        train_util.append(train[k])\n",
    "        target_train_util.append(target_train[k][0:5])\n",
    "\n",
    "train_data = np.array(train_util)[:20000]\n",
    "target_train = np.array(target_train_util)[:20000]\n",
    "\n",
    "validation_data = np.array(train_util)[20000:]\n",
    "target_validation = np.array(target_train_util)[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x261b0431550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x261b043dd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "r = rd.randint(0,train_data.shape[0])\n",
    "\n",
    "sbn.heatmap(train_data[r].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [[1,2,3,5,9,4]]\n",
    "B = [1,1,3,5,9,5]\n",
    "R = np.append(L,B)\n",
    "np.sum(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_results(results):\n",
    "    out = []\n",
    "    for result in results:\n",
    "        preprocessed_vector = np.zeros(result.shape)\n",
    "        index_max = result.argmax()\n",
    "        preprocessed_vector[index_max] = 1\n",
    "        out.append(preprocessed_vector)\n",
    "    return(out)\n",
    "\n",
    "def validation_step(results,targets):\n",
    "    results_util = np.array(preprocess_results(results))\n",
    "    assert results_util.shape == targets.shape\n",
    "    answer_array = results_util*targets\n",
    "    good_results = 0\n",
    "    for answer in answer_array:\n",
    "        n = np.sum(answer)\n",
    "        if n:\n",
    "            good_results +=1\n",
    "    return(good_results/targets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8038, 5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1723065439163971"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_step(out,target_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_nets(data = None, target=None,training = False):\n",
    "    tf.reset_default_graph() \n",
    "    nbr_epoch = 50\n",
    "    batch_size = 128\n",
    "    input_nn = tf.placeholder('float',shape=(None,784))\n",
    "    if training:\n",
    "        target_nn = tf.placeholder('float',shape = (None,5))\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer(mode = 'FAN_AVG')\n",
    "    with tf.name_scope('layer_1'):\n",
    "        hidden_1 = tf.layers.dense(input_nn,100,kernel_initializer=he_init,name='first_layer')\n",
    "        activation_1 = tf.nn.elu(hidden_1, name= 'activation_1')\n",
    "        normed_1 = tf.layers.batch_normalization(activation_1,name = 'normed_1', training = training)\n",
    "    with tf.name_scope('layer_2'):\n",
    "        hidden_2 = tf.layers.dense(normed_1,100,kernel_initializer=he_init,name='second_layer')\n",
    "        activation_2 = tf.nn.elu(hidden_2, name= 'activation_2')\n",
    "        normed_2 = tf.layers.batch_normalization(activation_2,name = 'normed_2', training = training)\n",
    "    with tf.name_scope('layer_3'):\n",
    "        hidden_3 = tf.layers.dense(normed_2,100,kernel_initializer=he_init,name='third_layer')\n",
    "        activation_3 = tf.nn.elu(hidden_3, name= 'activation_3')\n",
    "        normed_3 = tf.layers.batch_normalization(activation_3,name = 'normed_3', training = training)\n",
    "\n",
    "    with tf.name_scope('layer_4'):\n",
    "        hidden_4 = tf.layers.dense(normed_3,100,kernel_initializer=he_init,name='fourth_layer')\n",
    "        activation_4 = tf.nn.elu(hidden_4, name= 'activation_4')\n",
    "        normed_4 = tf.layers.batch_normalization(activation_4,name = 'normed_4', training = training)\n",
    "    \n",
    "    with tf.name_scope('layer_5'):\n",
    "        hidden_5 = tf.layers.dense(normed_4,100,kernel_initializer=he_init,name='fifth_layer')\n",
    "        activation_5 = tf.nn.elu(hidden_5, name= 'activation_5')\n",
    "        normed_5 = tf.layers.batch_normalization(activation_5,name = 'normed_5', training = training)\n",
    "\n",
    "    with tf.name_scope('output_layer'):\n",
    "        output = tf.layers.dense(activation_5,5,kernel_initializer=he_init,name='last_hidden')\n",
    "        logits = tf.nn.softmax(output)\n",
    "\n",
    "    if training:\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.name_scope('loss_calculation'):\n",
    "            error = tf.nn.softmax_cross_entropy_with_logits(logits = logits,labels = target_nn, name = 'error')\n",
    "            loss = tf.reduce_mean(error,name='loss')\n",
    "\n",
    "        with tf.name_scope('optimization'):\n",
    "            optimizer = tf.train.AdamOptimizer()\n",
    "            train_op = optimizer.minimize(loss)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    if training:\n",
    "        with tf.Session() as sess:\n",
    "            saver = tf.train.Saver()\n",
    "            sess.run(init)\n",
    "            best_validation = 0\n",
    "            index_validation = 0\n",
    "            for epoch in range(nbr_epoch):\n",
    "                save_path = saver.save(sess, \"/model/model.ckpt\")\n",
    "                for k in range(train_data.shape[0]//batch_size):\n",
    "                    X_batch = train_data[k*batch_size:(k+1)*batch_size]\n",
    "                    Y_batch = target_train[k*batch_size:(k+1)*batch_size]\n",
    "                    sess.run([train_op,extra_update_ops], feed_dict={input_nn:X_batch,target_nn:Y_batch})\n",
    "                    validation_logits = sess.run([logits], feed_dict={input_nn:validation_data})\n",
    "                    test_on_validation = validation_step(validation_logits[0],target_validation)\n",
    "                    index_validation +=1\n",
    "                    if test_on_validation > best_validation:\n",
    "                        best_validation = test_on_validation\n",
    "                        index_validation = 0\n",
    "                    if index_validation > 1000:\n",
    "                        print('Training early stopped at epoch-> {} and batch step ->{} as validation step wasn\\'t improving. best score on validation --> {}'.format(epoch,k,best_validation))\n",
    "                        save_path = saver.save(sess, \"/model/model_final.ckpt\")\n",
    "                        return()\n",
    "                print('Validation score for the epoch {} is -> {}'.format(epoch,best_validation))\n",
    "                if epoch % 5 == 0:\n",
    "                    print('Model saved after epoch -> {} @ {}'.format(epoch,save_path))\n",
    "            save_path = saver.save(sess, \"/model/model_final.ckpt\")\n",
    "            return('Model end training with best validation score -> {}'.format(best_validation))\n",
    "    else:\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            result = sess.run([logits], feed_dict = {input_nn:data})\n",
    "            return(result)\n",
    "    #Don't forget to put save.saver(path_fichier) dans la session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score for the epoch 0 is -> 0.9762378701169445\n",
      "Model saved after epoch -> 0 @ /model/model.ckpt\n",
      "Validation score for the epoch 1 is -> 0.98283155013685\n",
      "Validation score for the epoch 2 is -> 0.983578004478726\n",
      "Validation score for the epoch 3 is -> 0.9849465041054989\n",
      "Validation score for the epoch 4 is -> 0.9868126399601891\n",
      "Validation score for the epoch 5 is -> 0.9873102761881065\n",
      "Model saved after epoch -> 5 @ /model/model.ckpt\n",
      "Validation score for the epoch 6 is -> 0.9873102761881065\n",
      "Validation score for the epoch 7 is -> 0.9873102761881065\n",
      "Validation score for the epoch 8 is -> 0.9879323214730032\n",
      "Validation score for the epoch 9 is -> 0.9883055486439413\n",
      "Validation score for the epoch 10 is -> 0.9883055486439413\n",
      "Model saved after epoch -> 10 @ /model/model.ckpt\n",
      "Validation score for the epoch 11 is -> 0.9883055486439413\n",
      "Validation score for the epoch 12 is -> 0.9886787758148793\n",
      "Validation score for the epoch 13 is -> 0.9886787758148793\n",
      "Validation score for the epoch 14 is -> 0.988927593928838\n",
      "Validation score for the epoch 15 is -> 0.989300821099776\n",
      "Model saved after epoch -> 15 @ /model/model.ckpt\n",
      "Validation score for the epoch 16 is -> 0.9894252301567554\n",
      "Validation score for the epoch 17 is -> 0.9894252301567554\n",
      "Validation score for the epoch 18 is -> 0.9894252301567554\n",
      "Validation score for the epoch 19 is -> 0.9894252301567554\n",
      "Validation score for the epoch 20 is -> 0.9894252301567554\n",
      "Model saved after epoch -> 20 @ /model/model.ckpt\n",
      "Validation score for the epoch 21 is -> 0.9910425478974869\n",
      "Validation score for the epoch 22 is -> 0.9917890022393631\n",
      "Validation score for the epoch 23 is -> 0.9917890022393631\n",
      "Validation score for the epoch 24 is -> 0.9917890022393631\n",
      "Validation score for the epoch 25 is -> 0.9917890022393631\n",
      "Model saved after epoch -> 25 @ /model/model.ckpt\n",
      "Validation score for the epoch 26 is -> 0.9917890022393631\n",
      "Validation score for the epoch 27 is -> 0.9917890022393631\n",
      "Validation score for the epoch 28 is -> 0.9917890022393631\n",
      "Training early stopped at epoch-> 29 and batch step ->3 as validation step wasn't improving. best score on validation --> 0.9917890022393631\n"
     ]
    }
   ],
   "source": [
    "out = neural_nets(training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Training early stopped at epoch-> 26 and batch step ->17 as validation step wasn't improving. best score on validation --> 0.9876835033590445\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = neural_nets(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [0.977855187857676,0.9807165961682011,0.9844488678775815,0.9845732769345609,0.9845732769345609,0.9845732769345609,0.9865638218462304,0.9876835033590445,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_neural_nets():\n",
    "    graph = tf.get_default_graph()\n",
    "    new_hidden_1 = graph.get_tensor_by_name()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
